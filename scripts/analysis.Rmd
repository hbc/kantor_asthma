<!--
Analysis of anthrax infected cells vs. control cells
-->
```{r setup, echo=FALSE}
opts_chunk$set(tidy=TRUE, highlight=TRUE, fig.align='left', fig.show='hold',
               cache=FALSE, highlight=TRUE, autodep=TRUE, warning=FALSE, error=FALSE,
               message=FALSE, prompt=TRUE, comment='', fig.cap='')
```

# Overview
This project is looking at fifteen sets of blood samples with two sets of
blood samples from each patient. The first sample is at the time of an
asthma exacerbation and the other is taken months later when the patient
has returned to normal. The main factor of interest is what is different
in the blood in the exacerbated vs. the baseline state. This is likely to
be complex because there are large changes in the cellular composition
of the blood during the two states which must be controlled for. In addition
there are some other covariates that might have to get controlled for such
as rhinovirus infection.

# Setup
First thing to do is to load in the libraries we will use and massage the
data a bit to be in a format that is easier to work with. Below we make
sure all of the identifiers are congruent and convert the columns of
data to be what they are expected to be. We also load in and reformat
a table of metadata about each sample which we will use as regressors
later on.

```{r load-data, cache=TRUE}
library(dplyr)
library(extrafont)
library(xtable)
library(googleVis)
library(CHBUtils)
library(edgeR)
library(HTSFilter)
library(ggplot2)
library(gridExtra)
library(vsn)
library(DESeq2)
library(reshape)
wd = "/Users/rory/cache/kantor_asthma/scripts"
setwd(wd)
metadata_file = "/Users/rory/hsph/hsph/projects/kantor_asthma_rnaseq/data/asthma_full.csv"
metadata = read.csv(metadata_file, header=TRUE, colClasses="factor")
metadata$samplename = gsub("-", "_", metadata$samplename, fixed=T)
count_file = "/Users/rory/hsph/hsph/projects/kantor_asthma_rnaseq/asthma_project/final/131126_asthma_project/combined.counts"
counts = read.table(count_file, header=TRUE, sep="\t")
colnames(counts) = gsub(".", "_", colnames(counts), fixed=T)
rownames(counts) = counts$id
counts$id = NULL
samples = data.frame(samplename=colnames(counts))
samples = merge(samples, metadata, by="samplename", sort=FALSE)
samples$patient_status = paste(samples$patient, samples$status, sep="_")
rownames(samples) = samples$patient_status
colnames(samples) = gsub(".", "_pct", colnames(samples), fixed=T)
colnames(counts) = samples$patient_status

# convert the numeric columns to numbers instead of factors
numeric_columns = c("WBC", "Hgb", "Hct_pct", "Plt", "ANC",
    "ALC", "AEC", "Neut_pct", "Lymph_pct", "Mono_pct", "Eos_pct", "Baso_pct")
for (col in numeric_columns) {
    samples[,col] = as.numeric(as.character(samples[,col]))
}
```

We are left with a table of counts and some metadat about all of the samples:

```{r data-setup, results='asis'}
print(xtable(samples), "html")
print(xtable(head(counts)), "html")
```

We also will define a couple of utility functions we'll use to add some
context to the data.
```{r utility-functions}
ensembl_gene = "hsapiens_gene_ensembl"
filter_type = "ensembl_gene_id"
gene_symbol = "hgnc_symbol"
annotate_df = function(d) {
	require(biomaRt)
	ensembl = useMart('ensembl', dataset = ensembl_gene)
	a = getBM(attributes=c(filter_type, gene_symbol, "description"),
		filters=c(filter_type), values=rownames(d),
		mart=ensembl)
	m = merge(d, a, by.x="row.names", by.y=filter_type)
	return(m)
}
```

And some genes that we are expecting to see:

```{r expected-genes}
expected = c("CDHR3", "PDE4D", "DENND1B", "RAD50", "IL13",
 "IL1RL1", "IL2RL1", "IL3RL1", "IL4RL1", "IL5RL1", "IL6RL1",
 "IL7RL1", "IL8RL1", "IL9RL1", "IL10RL1", "IL11RL1", "IL12RL1",
 "IL13RL1", "IL14RL1", "IL15RL1", "IL16RL1", "IL17RL1",
 "IL18RL1", "IL33", "RORA", "SMAD3", "IL2RB", "TSLP-WDR36",
 "PYHIN1", "ADRA1B", "DPP10", "PRNP")
```

# Exploratory analysis
Looking at the data qualitatively is helpful for spotting any
outliers and seeing if the data makes sense. We will use some of the
plots in the libraries DESeq and edgeR along with some custom-made
plots to do this.

Since the range of the data is so huge, (0 - `r max(counts)`) for this
type of exploratory data analysis it is usually useful to work on
transformed versions of the data, otherwise a relatively small change
in a gene highly expessed will dwarf everything else.

A first sanity check is to see which genes are soaking up so many reads.
Millions of reads for a single gene is a concerning amount of reads to be
mapping to one gene.

```{r high-count-genes, results='asis'}
library(xtable)
print(xtable(annotate_df(counts[rowSums(counts) > 10000000,])), "html")
```

Hemoglobin genes make sense for this project, it would be really
disappointing if these were rRNA or some other type of contaminant we
aren't interested in.

The libraries are a little bit deeper than is optimal in terms of
maximizing the benefit of more reads vs the cost of sequencing,
averaging `r mean(colSums(counts))` reads mapping to genes per
sample. However since a small number of genes are soaking up a lot of
the reads, the libraries are close to the sweet spot of 15-20 million
reads per sample in terms of what is usable. If experiments are run on
blood in the future, it might be worth investigating ways of pulling out
the hemoglobin transcripts prior to sequencing so not as much of the
sequencing is wasted on them.

## Two patients are missing a sample
Patient A006 and patient A072 both had samples that failed. A006 is missing
their baseline sample and A072 is missing their exacerbation sample. Missing
the sample will make it so later on we can't do some comparisons because
the design matrix of our experiment won't be full rank, so we should drop
these samples unless there is an objection to doing that.

```{r drop-incomplete-samples}
samples = subset(samples, ! patient %in% c("A072", "A006"))
samples = droplevels(samples)
counts = counts[, colnames(counts) %in% samples$patient_status]
```

## Raw counts have some systematic deviation
We expect RNA-seq samples to have a similar distribution of gene expression,
although the actual genes that are expressed might be different. These samples
seem to have a systematic difference in exacerbated/baseline status:

```{r boxplot-raw}
melted = melt(counts)
colnames(melted) = c("sample", "count")
melted$count = log(melted$count)
ggplot(melted, aes(x=sample, y=count)) + geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Using trimmed mean of M-values (TMM) normalization reduces the
systematic difference quite a bit. The differential expression
algorithm we will use implemented in the library edgeR uses this
method to normalize.

```{r boxplot-normalized}
y = DGEList(counts = counts)
y = calcNormFactors(y)
normalized_counts = cpm(y, normalized.lib.sizes=TRUE)
melted = melt(normalized_counts)
colnames(melted) = c("gene", "sample", "count")
melted$count = log(melted$count)
ggplot(melted, aes(x=sample, y=count)) + geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Variance stabilization
For RNA-seq data it is hard to call differentially expressed genes for
genes with very low read counts because the variance of genes with
very low counts is enormous:

```{r edgeR-dispersions, cache=TRUE}
design = model.matrix(~ 0 + patient + status, data=samples)
y = DGEList(counts = counts)
y = calcNormFactors(y)
y = estimateGLMCommonDisp(y, design, verbose=TRUE)
y = estimateGLMTrendedDisp(y, design)
y = estimateGLMTagwiseDisp(y, design)
bcv(y)
```


So when we are looking at differentially expressed genes later on,
focusing on genes with not an extremely low count is prudent.

Also, for RNA-seq experiments in general there is a marked
relationship between the mean expression level of a gene and the
variance of the gene. When performing differential expression
we'll work with the raw counts, but for qualitative visualiation, applying a variance stablizing transformation to the data, which removes the component of the variance that is dependent on the mean value, is useful.  For this data set a simple log transformation of the data smooths the variance out quite a bit:

```{r variance-stabilization, cache=TRUE, fig.keep='all'}
dds = DESeqDataSetFromMatrix(countData=counts, colData=samples,
    design = ~ patient + status)
dds <- estimateSizeFactors(dds)
rld = rlogTransformation(dds, blind=TRUE)
notAllZero = rowSums(counts(dds)) > 0
par(mfrow = c(1, 2))
meanSdPlot(log2(counts(dds, normalized=TRUE)[notAllZero,] + 1))
meanSdPlot(assay(rld[notAllZero,]))
```

The effect of the variance stablizing transformation on visualization of
the data can be seen by looking at clustering of the samples based on
Euclidean distance. This is the non-transformed data:

```{r heatmap-novst}
dists = dist(t(counts))
mat = as.matrix(dists)
rownames(mat) = colnames(mat) = colnames(counts)
library(gplots)
heatmap.2(mat, trace="none")
```

with the variance stabilized data, we can see clear clustering on the
baseline and exacerbation status of the samples:
    
```{r heatmap-vst}
dists = dist(t(assay(rld)))
mat = as.matrix(dists)

library(gplots)
heatmap.2(mat, trace="none")

rownames(mat) = samples$virus_status
heatmap.2(mat, trace="none")
```

We can also see the effect of the transformation on the MDS plots. With
the raw data they look like this:
```{r mds-plots}
mds(counts, samples$status)
```

But using the variance transforming stabilization we can see the clear separation between the exacerbated and baseline samples along the first principal component. The plot on the left shows the proportion of the variance explained by each principal component:

```{r mds-transformed}
par(mfrow=c(1,2))
mds(assay(rld), samples$status)
variance_by_component(assay(rld))
```

# Simple differential expression
From the exploratory analysis we are expecting to see quite a few genes
that are different between the baseline and exacerbated experimental
conditions. It is useful to start with a simple model and gradually add
complexity to the model, so to start we will fit a model that fits
**patient** and **status**, blocking on **patient**.

First things first, we want to remove those low count high variance genes
from consideration. Removing these genes chops off the hugely variant
genes at the low end of expression and lets us work with a set of genes
we can be more confident about.

```{r discard-low-count-high-variance}
keep = rowSums(log2(cpm(counts)) > -2.5) >= 4
counts = counts[keep,]
table(keep)
design = model.matrix(~ patient + status, data=samples)
y = DGEList(counts = counts)
y = calcNormFactors(y)
y = estimateGLMCommonDisp(y, design, verbose=TRUE)
y = estimateGLMTrendedDisp(y, design)
y = estimateGLMTagwiseDisp(y, design)
bcv(y)
```

This dataset is paired, with a baseline and exacerbated status
for each patient and we will adjust for the patient during the differential
expression analysis. It is interesting to ask whether or not it is even
necessary to do that. All of our analysis is going to use a model where
we fit a GLM blocking on patient, so first do that:

```{r edgeR-fit}
design = model.matrix(~ 0 + patient + status, data=samples)
rownames(design) = colnames(counts)
y = DGEList(counts=counts)
y = calcNormFactors(y)
y = estimateGLMCommonDisp(y, design, verbose=TRUE)
y = estimateGLMTrendedDisp(y, design)
y = estimateGLMTagwiseDisp(y, design)
bcv(y)
fit = glmFit(y, design)
```

Now we can test for any differential expression at the patient level:

```{r patient-de, results='asis'}
lrt = glmLRT(fit, coef=1:14)
FDR = p.adjust(lrt$table$PValue, method="BH")
print(xtable(topTags(lrt)$table), "html")
```

There are `r sum(FDR < 0.05)` genes differentially expressed between
patients, so blocking on patient is a good plan.

Going ahead and doing a differential expression test on the exacerbation
status, blocking on patient:

```{r status-de}
lrt = glmLRT(fit, coef=15)
FDR = p.adjust(lrt$table$PValue, method="BH")
de = lrt$table
de$FDR = FDR
de = subset(de, FDR < 0.05)
de = annotate_df(de)
de = de[with(de, order(FDR)),]
de$id = de$Row.names
de$Row.names = NULL
```

gives us `r sum(FDR < 0.05)` genes differentially expressed.
From the whole blood cell counts we were expecting
large changes in cell type composition in the blood, so seeing this many
differentially expressed genes was expected. 

# Incorporating rhinovirus and other co-variates
If we want to incorporate the rhinovirus status and other co-variants
into the analysis, then I think we have to 
move away from using edgeR-- there are some things that none
of the RNA-seq specific differential expression callers can do, and
one of those things is to handle more complicated multi-level
experiments. Fortunately, we can use limma to do that. Here we create
a very simple model where the expression depends on the rhinovirus
status of the patient as well as the baseline/exacerbation status:

```{r limma-setup}
library(limma)
samples$virus_status = factor(paste(samples$rhinovirus, samples$status, sep="_"))
design = model.matrix(~ 0 + virus_status, data=samples)
colnames(design) = levels(samples$virus_status)
y = DGEList(counts=counts)
y = calcNormFactors(y)
v = voom(y, design, plot=TRUE)
corfit = duplicateCorrelation(v, design, block=samples$patient)
```

From the correlation fit we can estimate the correlation on comparisons made
within the same patient as `r corfit$consensus`. This is low but given the
large changes in gene expression from the **exacerbated** and **baseline**
statuses, this makes sense.

Now we can input that correlation into the linear model fit and look at
three comparisons:

1. **rhinovirus:** by comparing the rhinovirus positive exacerbated samples
   to the rhinovirus negative exacerbated samples
2. **exacerbation:** by comparing the rhinovirus negative exacerbated samples
   to the baseline samples
3. **rhinovirus_exacerbation:** by comparing the rhinovirus positive exacerbated
   samples to the baseline samples
    
    
```{r virus-exacerbated-analysis}
fit = lmFit(v, design, block=samples$patient, correlation=corfit$consensus)
cm = makeContrasts(
        rhinovirus = positive_exacerbation - negative_exacerbation,
        exacerbation = negative_exacerbation - negative_baseline,
        rhinovirus_exacerbation = positive_exacerbation - negative_baseline,
    levels=design)
fit2 = contrasts.fit(fit, cm)
fit2 = eBayes(fit2)
```

##qqt(fit2$t,df=fit2$df.prior+fit2$df.residual,pch=16,cex=0.1)

There are `r dim(topTable(fit2, n=Inf,p.value=0.05, coef="rhinovirus"))[1]` genes different in the **rhinovirus** comparison, `r dim(topTable(fit2, n=Inf,p.value=0.05, coef="exacerbation"))[1]` genes differentially in the **exacerbation** only condition
and 
`r dim(topTable(fit2, n=Inf,p.value=0.05, coef="rhinovirus_exacerbation"))[1]` genes differentially expressed in the **rhinovirus_exacerbation** condition. Again,
there are large changes in cell types between the exacerbated and baseline
conditions that will need to be corrected for.

## Simple differential expression wrapup 
The gene sets different in the baseline/exacerbated status are large
because it is likely there are different populations of cells in the
blood at the exacerbated and baseline timepoints. Luckily we have some
measurements of the cell types in the blood and we can do a quick
check if the measured cell types in the blood can predict anything about
the **exaceration/baseline** status of the samples. The first way to
visualize that is to cluster subset of the sample table on
those measurements. First we need to massage the
sample table to only keep numerical values and make a heatmap:

```{r sample-clustering}
heatmap_samples = samples[, numeric_columns]
heatmap.2(as.matrix(heatmap_samples), scale="column", trace="none")
```

The clustering isn't particularly strong looking at the heatmap, 
but there seems to be some grouping of the
exacerbated and baseline samples together. The MDS plot shows the relationship
much clearer with a nice clear separation along the second principal component:

```{r sample-mds-plot}
mds(t(heatmap_samples), samples$status)
```

Correcting for differences in cell type composition is likely a good idea.
It would be really helpful to know which aspects of the cell type
composition are causing the separation we see on the MDS plot. To do that
we will fit a logistical model to the data. We should first try to
scale the regressors so they are on a similar scale. To do that we'll
convert the regressors to Z-scores so each value is the number of
standard deviations from the mean value for the regressor. This has
the effect of separating the samples by **status** along the first
principal component.
    
```{r z-score-conversion}
z_score = function(x) {
  return((x - mean(x)) / sd(x))
}
samples_norm = samples
for (col in numeric_columns) {
  samples_norm[, col] = z_score(samples[, col])
}
mds(t(samples_norm[, numeric_columns]), samples$status)
```

And now we will fit a logistical model using those WBC predictors:
    
```{r logit-model, warnings=TRUE}
logit = glm(status ~ rhinovirus + WBC + Hgb + Hct_pct + Plt + ANC +
   ALC + AEC + Neut_pct + Lymph_pct + Mono_pct + Eos_pct + Baso_pct,
   family="binomial", data=samples_norm)
form = status ~ WBC + Hct_pct + Hgb + Plt + ANC + AEC + ALC
logit = glm(form, data=samples, family="binomial")
summary(logit)
```

The residual deviance is extremely small,
that generally happens when one of the predictors in the model can classify the samples perfectly. If that is true we can see which predictor has that feature by making a decision tree using the same model we used for the logistical regression:

```{r decision-tree}
library(rpart)
rpart(form, data=samples)
```

We can see that splitting the samples on standardized $ALC >= 1.935$
partitions the samples into **exacerbated** and **baseline** status.

For now we will drop that from the model to see what other factors might
be involved:

```{r non-alc-model}
form = status ~ WBC + Hct_pct + Hgb + Plt + ANC + AEC
logit = glm(form, data=samples, family="binomial")
summary(logit)
```

This time ANC is a perfect predictor:
    
```{r second-decision-tree}
library(rpart)
rpart(form, data=samples)
```

Dropping ANC lets us find the other factors that we might have to correct for:
```{r simple-model}
form = status ~ WBC + Hct_pct + Hgb + Plt + AEC
logit = glm(form, data=samples, family="binomial")
summary(logit)
```

So, just based on the metadata provided,  a set of factors that we expect to
have an effect on gene expression in the exacerbated/baseline stamples are
$$rhinovirus + WBC + AEC + ANC + ALC$$. 

# Naive cell-type corrected differential expression 
For the first shot, we will use all of the standardized whole blood measurements as
regressors in the model, ignoring what we did above to pick out the most
important ones:

```{r naive-de}
design = model.matrix(~ 0 + WBC + Hct_pct + Hgb +
    Plt + AEC + ANC + ALC + Neut_pct + Baso_pct + virus_status, data=samples_norm)
colnames(design) = c("WBC", "Hct_pct", "Hgb", "Plt", "AEC", "ANC", "ALC",
    "Neut_pct", "Baso_pct", "negative_baseline", "negative_exacerbation",
    "positive_exacerbation")
```

And look at the same comparisons as we did before without correcting for
the whole blood measurements:
    
1. **rhinovirus:** by comparing the rhinovirus positive exacerbated samples
   to the rhinovirus negative exacerbated samples
2. **exacerbation:** by comparing the rhinovirus negative exacerbated samples
   to the baseline samples
3. **rhinovirus_exacerbation:** by comparing the rhinovirus positive exacerbated
   samples to the baseline samples

```{r naive-analysis}
cm = makeContrasts(
        rhinovirus = positive_exacerbation - negative_exacerbation,
        exacerbation = negative_exacerbation - negative_baseline,
        rhinovirus_exacerbation = positive_exacerbation - negative_baseline,
    levels=design)
y = DGEList(counts=counts)
y = calcNormFactors(y)
v = voom(y, design)
corfit = duplicateCorrelation(v, design, block=samples$patient)
fit = lmFit(v, design, block=samples$patient, correlation=corfit$consensus)
fit2 = contrasts.fit(fit, cm)
fit2 = eBayes(fit2)
```
There are `r dim(topTable(fit2, coef="exacerbation", n=Inf,p.value=0.05))[1]`
genes different in the **exacerbation** comparison, 
`r dim(topTable(fit2, coef="rhinovirus", n=Inf,p.value=0.05))[1]`
genes different in the **rhinovirus** comparison and
`r  dim(topTable(fit2, coef="rhinovirus_exacerbation", n=Inf,p.value=0.05))[1]`
genes different in the 
the exacerbated samples alone. 

We've wiped out most of our signal by trying to simultaneously control for
so many factors. If we just include the regressors that we deemed to be
important, there are a couple more hits:

```{r controlled-de}
design = model.matrix(~ 0 + WBC + AEC + ANC + ALC +
    virus_status, data=samples_norm)
colnames(design) = c("WBC", "AEC", "ANC", "ALC",
    "negative_baseline", "negative_exacerbation",
    "positive_exacerbation")
cm = makeContrasts(
        rhinovirus = positive_exacerbation - negative_exacerbation,
        exacerbation = negative_exacerbation - negative_baseline,
        rhinovirus_exacerbation = positive_exacerbation - negative_baseline,
    levels=design)
y = DGEList(counts=counts)
y = calcNormFactors(y)
v = voom(y, design, plot=TRUE)
corfit = duplicateCorrelation(v, design, block=samples$patient)
fit = lmFit(v, design, block=samples$patient, correlation=corfit$consensus)
fit2 = contrasts.fit(fit, cm)
fit2 = eBayes(fit2)
```

There are `r dim(topTable(fit2, coef="exacerbation", n=Inf,p.value=0.05))[1]`
genes different between the samples in the baseline and exacerbated state.

There are  `r dim(topTable(fit2, coef="rhinovirus", n=Inf,p.value=0.05))[1]`
genes different in the rhinovirus comparison.


The model seems to capture a lot of the main features of the data,
even if we only include a subset of the factors.  Surrogate Variable
Analysis (SVA) removes systematic differences in data by performing
SVD on the residuals of a model fit and determining if the identified
eigensystems are due to chance via permutation.

`{r sva}
library(sva)
n.sv = num.sv(v$E, design, method="leek")
```

SVA detects `r n.sv` systematic unmodeled variables that need to be adjusted
for in the data so it seems like we are capturing the major effects.


# Revisiting edgeR
EdgeR models the count data as negative binomial distributed instead of
first transforming the data to continuous pseudo-expression values.
We saw above that logging the data did not completely smooth out the
mean-variance relationship in the data, so it is possible we are losing some
power to detect differentially regulated genes using limma. Using edgeR
fixes that problem but we lose some of the ability to handle things like
multi-level models.

```{r edger-revisited, results='asis'}
design = model.matrix(~ 0 + patient + rhinovirus + WBC + Hct_pct + Hgb + Plt +
    AEC +  Neut_pct + Baso_pct + status, data=samples_norm)
rownames(design) = colnames(counts)
y = DGEList(counts=counts)
y = calcNormFactors(y)
y = estimateGLMCommonDisp(y, design, verbose=TRUE)
y = estimateGLMTrendedDisp(y, design)
y = estimateGLMTagwiseDisp(y, design)
bcv(y)
fit = glmFit(y, design)
lrt = glmLRT(fit, coef=23)
FDR = p.adjust(lrt$table$PValue, method="BH")
de = lrt$table
de$FDR = FDR
de = subset(de, FDR < 0.05)
de = annotate_df(de)
de = de[with(de, order(FDR)),]
de$id = de$Row.names
de$Row.names = NULL
print(xtable(de), "html")
```

None of these genes are in the expected set either though.
