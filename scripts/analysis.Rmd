<!--
Analysis of anthrax infected cells vs. control cells
-->
```{r setup, echo=FALSE}
opts_chunk$set(tidy=TRUE, highlight=TRUE, fig.align='left', fig.show='hold',
               cache=FALSE, highlight=TRUE, autodep=TRUE, warning=FALSE, error=FALSE,
               message=FALSE, prompt=TRUE, comment='', fig.cap='')
```

# Overview
This project is looking at fifteen sets of blood samples with two sets of
blood samples from each patient. The first sample is at the time of an
asthma exacerbation and the other is taken months later when the patient
has returned to normal. The main factor of interest is what is different
in the blood in the exacerbated vs. the baseline state. There are some
other covariates they would like to look at too such as a positive
test for rhinovirus, CBC (complete blood count), etc.

```{r load-data, cache=TRUE}
library(dplyr)
library(extrafont)
library(xtable)
library(googleVis)
library(CHBUtils)
library(edgeR)
library(HTSFilter)
library(ggplot2)
library(gridExtra)
library(vsn)
library(DESeq2)
library(reshape)
wd = "/Users/rory/cache/kantor_asthma/scripts"
setwd(wd)
metadata_file = "/Users/rory/hsph/hsph/projects/kantor_asthma_rnaseq/data/asthma_full.csv"
metadata = read.csv(metadata_file, header=TRUE, colClasses="factor")
metadata$samplename = gsub("-", "_", metadata$samplename, fixed=T)
count_file = "/Users/rory/hsph/hsph/projects/kantor_asthma_rnaseq/asthma_project/final/131126_asthma_project/combined.counts"
counts = read.table(count_file, header=TRUE, sep="\t")
colnames(counts) = gsub(".", "_", colnames(counts), fixed=T)
rownames(counts) = counts$id
counts$id = NULL
samples = data.frame(samplename=colnames(counts))
samples = merge(samples, metadata, by="samplename", sort=FALSE)
samples$patient_status = paste(samples$patient, samples$status, sep="_")
rownames(samples) = samples$patient_status
colnames(samples) = gsub(".", "_pct", colnames(samples), fixed=T)
colnames(counts) = samples$patient_status

# convert the numeric columns to numbers instead of factors
numeric_columns = c("WBC", "Hgb", "Hct_pct", "Plt", "ANC",
    "ALC", "AEC", "Neut_pct", "Lymph_pct", "Mono_pct", "Eos_pct", "Baso_pct")
for (col in numeric_columns) {
    samples[,col] = as.numeric(as.character(samples[,col]))
}
```

First we need to load in the data and prepare some metadata about each of
the samples. R destroys some of the sample names so we have to do a little bit
of massaging to get everything working properly. We are left with a table of counts
and some metadata about all of the samples.

```{r data-setup, results='asis'}
#print(gvisTable(head(counts)), "chart")
#print(gvisTable(samples), "chart")
print(xtable(samples), "html")
print(xtable(head(counts)), "html")
```

We also will define a couple of utility functions we'll use to add some
context to the data.
```{r utility-functions}
ensembl_gene = "hsapiens_gene_ensembl"
filter_type = "ensembl_gene_id"
gene_symbol = "hgnc_symbol"
annotate_df = function(d) {
	require(biomaRt)
	ensembl = useMart('ensembl', dataset = ensembl_gene)
	a = getBM(attributes=c(filter_type, gene_symbol, "description"),
		filters=c(filter_type), values=rownames(d),
		mart=ensembl)
	m = merge(d, a, by.x="row.names", by.y=filter_type)
	return(m)
}
```

# Exploratory analysis
The first thing to do is to look at the data qualitatively to spot any
outliers and see if the data makes sense. We will use some of the
plots in the libraries DESeq and edgeR along with some custom made
plots to do this.

Since the range of the data is so huge, (0 - `r max(counts)`) for this
type of exploratory data analysis it is usually useful to work on
transformed versions of the data, otherwise a relatively small change
in a gene highly expessed will dwarf everything else.

A first sanity check is to see which genes are soaking up so many
reads.  Millions of reads for a single gene is a concerning amount
of reads to be mapping
to one gene.

```{r high-count-genes, results='asis'}
library(xtable)
print(xtable(annotate_df(counts[rowSums(counts) > 10000000,])), "html")
```

Hemoglobin genes make sense for this project, it would be really
disappointing if these were rRNA or some other type of contaminant we
aren't interested in.

The libraries are a little bit deeper than is optimal in terms of
maximizing the benefit of more reads vs the cost of sequencing,
averaging `r mean(colSums(counts))` reads mapping to genes per
sample. However since a small number of genes are soaking up a lot of
the reads, the libraries are close to the sweet spot of 15-20 million
reads per sample in terms of what is usable. If experiments are run on
blood in the future, it might be worth investigating ways of pulling out
the hemoglobin transcripts prior to sequencing so not as much of the
sequencing is wasted on them.

## Two patients are missing a sample
Patient A006 and patient A072 both had samples that failed. A006 is missing
their baseline sample and A072 is missing their exacerbation sample. Missing
the sample will make it so later on we can't do some comparisons because
the design matrix of our experiment won't be full rank, so we should drop
these samples unless there is an objection to doing that.

```{r drop-incomplete-samples}
samples = subset(samples, ! patient %in% c("A072", "A006"))
samples = droplevels(samples)
counts = counts[, colnames(counts) %in% samples$patient_status]
```

## Raw counts have some systematic deviation
We expect RNA-seq samples to have a similar distribution of gene expression,
although the actual genes that are expressed might be different. These samples
seem to have a systematic difference in exacerbated/baseline status:

```{r boxplot-raw}
melted = melt(counts)
colnames(melted) = c("sample", "count")
melted$count = log(melted$count)
ggplot(melted, aes(x=sample, y=count)) + geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Using trimmed mean of M-values (TMM) normalization reduces the
systematic difference quite a bit. The differential expression
algorithm we will use implemented in the library edgeR uses this
method to normalize.

```{r boxplot-normalized}
y = DGEList(counts = counts)
y = calcNormFactors(y)
normalized_counts = cpm(y, normalized.lib.sizes=TRUE)
melted = melt(normalized_counts)
colnames(melted) = c("gene", "sample", "count")
melted$count = log(melted$count)
ggplot(melted, aes(x=sample, y=count)) + geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Variance stabilization
For RNA-seq data it is hard to call differentially expressed genes for
genes with very low read counts because the variance of genes with
very low counts is enormous:

```{r edgeR-dispersions, cache=TRUE}
design = model.matrix(~ 0 + patient + status, data=samples)
y = DGEList(counts = counts)
y = calcNormFactors(y)
y = estimateGLMCommonDisp(y, design)
y = estimateGLMTrendedDisp(y, design)
y = estimateGLMTagwiseDisp(y, design)
bcv(y)
```

So when we are looking at differentially expressed genes later on,
focusing on genes with not an extremely low count is prudent.

Also, for RNA-seq experiments in general there is a marked
relationship between the mean expression level of a gene and the
variance of the gene. When performing differential expression
we'll work with the raw counts, but for qualitative visualiation, applying a variance stablizing transformation to the data, which removes the component of the variance that is dependent on the mean value, is useful.  For this data set a simple log transformation of the data smooths the variance out quite a bit:

```{r variance-stabilization, cache=TRUE, fig.keep='all'}
dds = DESeqDataSetFromMatrix(countData=counts, colData=samples,
    design = ~ patient + status)
dds <- estimateSizeFactors(dds)
rld = rlogTransformation(dds, blind=TRUE)
notAllZero = rowSums(counts(dds)) > 0
par(mfrow = c(1, 2))
meanSdPlot(log2(counts(dds, normalized=TRUE)[notAllZero,] + 1))
meanSdPlot(assay(rld[notAllZero,]))
```

The effect of the variance stablizing transformation on visualization of
the data can be seen by looking at clustering of the samples based on
Euclidean distance. Without stabilizing the variance a few highly expressed
variant genes skew the distance measure and make clustering fail. This
heatmap would give anyone a heart attack:

```{r heatmap-novst}
dists = dist(t(counts))
mat = as.matrix(dists)
rownames(mat) = colnames(mat) = colnames(counts)
library(gplots)
heatmap.2(mat, trace="none")
```

But with the variance stabilized data, we can see clear clustering on the
baseline and exacerbation status of the samples:
    
```{r heatmap-vst}
dists = dist(t(assay(rld)))
mat = as.matrix(dists)

library(gplots)
heatmap.2(mat, trace="none")
```

We can also see the effect of the transformation on the MDS plots. With
the raw data they look like this:
```{r mds-plots}
mds(counts, samples$status)
```

But using the variance transforming stabilization we can see the clear
separation between the exacerbated and baseline samples along the
first principal component, exactly what we were hoping to see. The
plot on the left shows the proportion of the variance explained by
each principal component:

```{r mds-transformed}
par(mfrow=c(1,2))
mds(assay(rld), samples$status)
variance_by_component(assay(rld))
```

# Simple differential expression
From the exploratory analysis we are expecting to see quite a few genes
that are different between the baseline and exacerbated experimental
conditions. It is useful to start with a simple model and gradually add
complexity to the model, so to start we will fit a model that fits
**patient** and **status**, blocking on patient.

First things first, we want to remove those low count high variance genes
from consideration. Removing these genes chops off the hugely variant
genes at the low end of expression and lets us work with a set of genes
we can be more confident about.

```{r discard-low-count-high-variance}
keep = rowSums(log2(cpm(counts)) > -2.5) >= 4
counts = counts[keep,]
table(keep)
design = model.matrix(~ patient + status, data=samples)
y = DGEList(counts = counts)
y = calcNormFactors(y)
y = estimateGLMCommonDisp(y, design)
y = estimateGLMTrendedDisp(y, design)
y = estimateGLMTagwiseDisp(y, design)
bcv(y)
```

This dataset is paired, with a baseline and exacerbated status
for each patient and we will adjust for the patient during the differential
expression analysis. It is interesting to ask whether or not it is even
necessary to do that. All of our analysis is going to use a model where
we fit a GLM blocking on patient, so first do that:

```{r edgeR-fit}
design = model.matrix(~ 0 + patient + status, data=samples)
rownames(design) = colnames(counts)
y = DGEList(counts=counts)
y = calcNormFactors(y)
y = estimateGLMCommonDisp(y, design, verbose=TRUE)
y = estimateGLMTrendedDisp(y, design)
y = estimateGLMTagwiseDisp(y, design)
bcv(y)
fit = glmFit(y, design)
```

Now we can test for differential expression at the patient level:

```{r patient-de, results='asis'}
lrt = glmLRT(fit, coef=1:14)
FDR = p.adjust(lrt$table$PValue, method="BH")
print(xtable(topTags(lrt)$table), "html")
```

There are `r sum(FDR < 0.05)` genes differentially expressed between
patients, so blocking on patient is a good plan.

Going ahead and doing a differential expression test on the exacerbation
status, blocking on patient:

```{r status-de}
lrt = glmLRT(fit, coef=15)
FDR = p.adjust(lrt$table$PValue, method="BH")
de = lrt$table
de$FDR = FDR
de = subset(de, FDR < 0.05)
de = annotate_df(de)
de = de[with(de, order(FDR)),]
de$id = de$Row.names
de$Row.names = NULL
```

gives us `r sum(FDR < 0.05)` genes differentially expressed.
That is a lot of genes, cutting down that list will be helpful. As
a hacky way of doing that, lets restrict to genes which have a
fairly robust level of expression and also have a fold change > 4:

```{r de-subset}
de_subset = subset(de, abs(logFC) > 2 & logCPM > 1)
```
That leaves us with a more manageable `r dim(de_subset)[1]` genes to look at.

Saving these two lists as TSV files:

```{r write-tables}
write.table(de, "de_full.tsv", quote=FALSE, row.names=FALSE, sep="\t")
write.table(de_subset, "de_subset.tsv", quote=FALSE, row.names=FALSE,
   sep="\t")
```


# Incorporating rhinovirus and other co-variates
If we want to incorporate the rhinovirus status and other co-variants into the analysis, then we'll
have to move away from using edgeR-- there are some things that none
of the RNA-seq specific differential expression callers can do, and
one of those things is to handle more complicated multi-level
experiments.  Fortunately, we can use limma to do that.

```{r limma-setup}
library(limma)
samples$virus_status = factor(paste(samples$rhinovirus, samples$status, sep="_"))
design = model.matrix(~ 0 + virus_status, data=samples)
colnames(design) = levels(samples$virus_status)
y = DGEList(counts=counts)
y = calcNormFactors(y)
v = voom(y, design, plot=TRUE)
corfit = duplicateCorrelation(v, design, block=samples$patient)
```

From the correlation fit we can estimate the correlation on comparisons made
within the same patient as `r corfit$consensus`. This is low but given the
large changes in gene expression from the **exacerbated** and **baseline**
statuses, this makes sense.

Now we can input that correlation into the linear model fit:
    
```{r exacerbated-analysis}
fit = lmFit(v, design, block=samples$patient, correlation=corfit$consensus)
cm = makeContrasts(
    RVPositive_vs_RVNegativeForExacerbated = positive_exacerbation - negative_exacerbation, levels=design)
fit2 = contrasts.fit(fit, cm)
fit2 = eBayes(fit2)
topTable(fit2, coef="RVPositive_vs_RVNegativeForExacerbated")
```

There are `dim(topTable(fit2, n=200,p.value=0.05, coef="RVPositive_vs_RVNegativeForExacerbated"))[1]` genes different between the rhinovirus positive and rhinovirus negative samples in the exacerbated state.

## Simple differential expression wrapup 
The gene sets different in the baseline/exacerbated status are large
because it is likely there are different populations of cells in the
blood at the exacerbated and baseline timepoints.  We can do a quick
check if that is true by clustering a subset of the sample table on
those measurements, similar to Figure 1 of the That is it for a first
pass differential expression analysis. First we need to massage the
sample table to only keep numerical values:

```{r sample-clustering}
heatmap_samples = samples[, numeric_columns]
heatmap.2(as.matrix(heatmap_samples), scale="column", trace="none")
```

The clustering isn't particularly strong looking at the heatmap, 
but there seems to be some grouping of the
exacerbated and baseline samples together. The MDS plot shows the relationship
much clearer with a nice clear separation along the second principal component:

```{r sample-mds-plot}
mds(t(heatmap_samples), samples$status)
```

Correcting for differences in cell type composition is likely a good idea.
It would be really helpful to know which aspects of the cell type
composition are causing the separation we see on the MDS plot. To do that
we will fit a logistical model to the data. We should first try to
scale the regressors so they are on a similar scale. To do that we'll
convert the regressors to Z-scores so each value is the number of
standard deviations from the mean value for the regressor. This has
the effect of separating the samples by **status** along the first
principal component.
    
```{r z-score-conversion}
z_score = function(x) {
  return((x - mean(x)) / sd(x))
}
samples_norm = samples
for (col in numeric_columns) {
  samples_norm[, col] = z_score(samples[, col])
}
mds(t(samples_norm[, numeric_columns]), samples$status)
```

And now we will fit a logistical model using those WBC predictors:
    
```{r logit-model, warnings=TRUE}
logit = glm(status ~ rhinovirus + WBC + Hgb + Hct_pct + Plt + ANC +
   ALC + AEC + Neut_pct + Lymph_pct + Mono_pct + Eos_pct + Baso_pct,
   family="binomial", data=samples_norm)
form = status ~ WBC + Hct_pct + Hgb + Plt + ANC + AEC + ALC
logit = glm(form, data=samples, family="binomial")
summary(logit)
```

Those warnings are a red flag. We can see the residual deviance is extremely small,
that generally happens when one of the predictors in the model can classify the
samples perfectly. If that is true we can see which predictor has that
feature by making a decision tree using the same model we used for the
logistical regression:

```{r decision-tree}
library(rpart)
rpart(form, data=samples)
```

We can see that splitting the samples on standardized $ALC >= 1.935$
perfectly classifies the samples into **exacerbated** and **baseline** status.

For now we will drop that from the model to see what other factors might
be involved:

```{r non-alc-model}
form = status ~ WBC + Hct_pct + Hgb + Plt + ANC + AEC
logit = glm(form, data=samples, family="binomial")
summary(logit)
```

This time ANC is a perfect predictor:
    
```{r second-decision-tree}
library(rpart)
rpart(form, data=samples)
```

Dropping ANC lets us find the other factors that we might have to correct for:
```{r simple-model}
form = status ~ WBC + Hct_pct + Hgb + Plt + AEC
logit = glm(form, data=samples, family="binomial")
summary(logit)
```

So a set of factors that are expected to have an effect on gene
expression status are $rhinovirus + WBC + AEC + ANC + ALC$.

# Cell-type corrected differential expression
The first thing we need to do is to place the regressors on some kind
of similar scale. Converting the values to Z-scores is one way to do that.

`{r corrected-de}
samples_norm$virus_status = factor(paste(samples_norm$rhinovirus,
    samples_norm$status, sep="_"))
#design = model.matrix(~ 0 + virus_status, data=samples)
design = model.matrix(~ 0 + Hct_pct + Hgb + Plt + AEC + status, 
    data=samples_norm)
y = DGEList(counts=counts)
y = calcNormFactors(y)
v = voom(y, design, plot=TRUE)
corfit = duplicateCorrelation(v, design, block=samples_norm$patient)
```

From the correlation fit we can estimate the correlation on
comparisons made within the same patient as `r corfit$consensus`. The
effect of controlling for the This is low but given the large changes
in gene expression from the **exacerbated** and **baseline** statuses,
this makes sense.

Now we can input that correlation into the linear model fit:
    
```{r exacerbated-analysis}
fit = lmFit(v, design, block=samples_norm$patient, correlation=corfit$consensus)
cm = makeContrasts(
    RVPositive_vs_RVNegativeForExacerbated = virus_statuspositive_exacerbation - virus_statusnegative_exacerbation, levels=design)
fit2 = contrasts.fit(fit, cm)
fit2 = eBayes(fit2)
dim(topTable(fit2, coef="RVPositive_vs_RVNegativeForExacerbated", p.value=0.05,n=Inf))
FDR = p.adjust(fit2$table$PValue, method="BH")

# below here is a check to just do this all in edgeR
design = model.matrix(~ 0 + patient + rhinovirus + WBC + Hct_pct + Hgb + Plt + AEC +
  + Neut_pct + Baso_pct + status, data=samples_norm)
rownames(design) = colnames(counts)
y = DGEList(counts=counts)
y = calcNormFactors(y)
y = estimateGLMCommonDisp(y, design, verbose=TRUE)
y = estimateGLMTrendedDisp(y, design)
y = estimateGLMTagwiseDisp(y, design)
bcv(y)
fit = glmFit(y, design)
lrt = glmLRT(fit, coef=22)
FDR = p.adjust(lrt$table$PValue, method="BH")
de = lrt$table
de$FDR = FDR
de = subset(de, FDR < 0.05)
de = annotate_df(de)
de = de[with(de, order(FDR)),]
de$id = de$Row.names
de$Row.names = NULL

expected = c("CDHR3", "PDE4D", "DENND1B", "RAD50", "IL13",
 "IL1RL1", "IL2RL1", "IL3RL1", "IL4RL1", "IL5RL1", "IL6RL1",
 "IL7RL1", "IL8RL1", "IL9RL1", "IL10RL1", "IL11RL1", "IL12RL1",
 "IL13RL1", "IL14RL1", "IL15RL1", "IL16RL1", "IL17RL1",
 "IL18RL1", "IL33", "RORA", "SMAD3", "IL2RB", "TSLP-WDR36",
 "PYHIN1", "ADRA1B", "DPP10", "PRNP")

We recover 'r sum(expected %in% de$hgnc_symbol)' of those expected genes.

Some of the hits show up though:

AREG: http://www.ncbi.nlm.nih.gov/pubmed/21036386

 
IL1RL1-IL18R1 (Moffatt et al. 2010; Torgerson et al. 2011)
GSDMB/ORMDL3 (Moffatt et al. 2010; Torgerson et al. 2011)
IL33 (Moffatt et al. 2010; Torgerson et al. 2011)
RORA (Moffatt et al. 2010)
SMAD3 (Moffatt et al. 2010)
IL2RB (Moffatt et al. 2010)
TSLP-WDR36) (Hirota et al. 2011; Torgerson et al. 2011)
PYHIN1 (Torgerson et al. 2011)
ADRA1B (Mathias et al. 2010)
DPP10 (Mathias et al. 2010)
PRNP (Mathias et al. 2010)
